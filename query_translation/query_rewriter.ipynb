{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use sample: True\n",
      "dataset: privacy_qa\n",
      "vector store: ./vectorstore/faiss_store_sample_privacy_qa\n",
      "corpus path: ../data/sample_corpus/privacy_qa\n",
      "test file: ../data/sample_benchmarks/privacy_qa.json\n",
      "rephrased file: ../data/sample_benchmarks_rephrased/privacy_qa.json\n",
      "generic file: ../data/sample_benchmarks_generic/privacy_qa.json\n"
     ]
    }
   ],
   "source": [
    "# Universal parameters\n",
    "_use_sample = True\n",
    "dataset_name = \"privacy_qa\"\n",
    "vectorstore_path = f\"./vectorstore/faiss_store_{'sample_' if _use_sample else ''}{dataset_name}\"\n",
    "directory_path = f\"../data/{'sample_' if _use_sample else ''}corpus/{dataset_name}\"\n",
    "test_file = f\"../data/{'sample_' if _use_sample else ''}benchmarks/{dataset_name}.json\"\n",
    "rephrased_file = f\"../data/{'sample_' if _use_sample else ''}benchmarks_rephrased/{dataset_name}.json\"\n",
    "generic_file = f\"../data/{'sample_' if _use_sample else ''}benchmarks_generic/{dataset_name}.json\"\n",
    "\n",
    "print(f\"use sample: {_use_sample}\")\n",
    "print(f\"dataset: {dataset_name}\")\n",
    "print(f\"vector store: {vectorstore_path}\")\n",
    "print(f\"corpus path: {directory_path}\")\n",
    "print(f\"test file: {test_file}\")\n",
    "print(f\"rephrased file: {rephrased_file}\")\n",
    "print(f\"generic file: {generic_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Tuple, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class QASnippet(BaseModel):\n",
    "    file_path: str\n",
    "    span: Tuple[int, int]\n",
    "    answer: str\n",
    "\n",
    "class QAGroundTruth(BaseModel):\n",
    "    query: str\n",
    "    snippets: List[QASnippet]\n",
    "    file_set: Optional[List[str]] = None\n",
    "\n",
    "def load_groundtruth(json_file_path: str) -> List[QAGroundTruth]:\n",
    "    \"\"\"\n",
    "    Loads the QA ground-truth data from a JSON file.\n",
    "    Expected JSON format:\n",
    "    [\n",
    "        {\n",
    "            \"query\": \"Your query...\",\n",
    "            \"snippets\": [\n",
    "                {\n",
    "                    \"file_path\": \"path/to/file.txt\",\n",
    "                    \"span\": [start, end],\n",
    "                    \"answer\": \"The answer text...\"\n",
    "                },\n",
    "                ...\n",
    "            ],\n",
    "            \"file_set\": [\n",
    "                \"file1.txt\", \"file2.txt\", ...\n",
    "            ]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    groundtruth_tests = []\n",
    "    \n",
    "    # Support both list-of-tests or dict with key \"tests\"\n",
    "    tests = data.get(\"tests\") if isinstance(data, dict) else data\n",
    "    \n",
    "    for test in tests:\n",
    "        snippets = [QASnippet(**snippet) for snippet in test.get(\"snippets\", [])]\n",
    "        file_set = test.get(\"file_set\")\n",
    "        groundtruth_tests.append(QAGroundTruth(query=test[\"query\"], snippets=snippets, file_set=file_set))\n",
    "    return groundtruth_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 461 document chunks with spans.\n",
      "FAISS vector store saved locally at './vectorstore/faiss_store_sample_privacy_qa'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\") \n",
    "\n",
    "# sentence-transformers/all-MiniLM-L6-v2\n",
    "# Linq-AI-Research/Linq-Embed-Mistral\n",
    "# thenlper/gte-base\n",
    "\n",
    "def load_documents_with_spans(directory: str, chunk_size: int = 1000, chunk_overlap: int = 0):\n",
    "    \"\"\"\n",
    "    Loads .txt files from a directory, splits each document's text into chunks using\n",
    "    RecursiveCharacterTextSplitter, computes the span (start, end) for each chunk, and\n",
    "    returns a list of Document objects with metadata (including filename, source, and span).\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    # Initialize the splitter with the desired separators and parameters.\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"!\", \"?\", \".\", \":\", \";\", \",\", \" \", \"\"],\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "        strip_whitespace=False,\n",
    "    )\n",
    "    \n",
    "    # Process each .txt file in the directory.\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            # Split text into chunks.\n",
    "            text_splits = splitter.split_text(text)\n",
    "            \n",
    "            # Verify that the chunks concatenate to the original text.\n",
    "            assert \"\".join(text_splits) == text, \"Concatenated splits do not match the original text.\"\n",
    "            \n",
    "            # Compute spans and create Document objects.\n",
    "            prev_index = 0\n",
    "            for i, chunk_text in enumerate(text_splits):\n",
    "                span = (prev_index, prev_index + len(chunk_text))\n",
    "                prev_index += len(chunk_text)\n",
    "                doc = Document(\n",
    "                    page_content=chunk_text,\n",
    "                    metadata={\n",
    "                        \"filename\": filename,\n",
    "                        \"filepath\": f\"{dataset_name}/{filename}\",\n",
    "                        \"span\": span,  # Stores the (start, end) positions of the chunk.\n",
    "                        \"id\": f\"{filename}_chunk_{i}\"\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "    return documents\n",
    "\n",
    "\n",
    "if os.path.exists(vectorstore_path):\n",
    "    print(f\"The vectorstore_path '{vectorstore_path}' already exists. Please delete it first if you wish to continue.\")\n",
    "else:\n",
    "    # Load the documents, splitting each into chunks with span metadata.\n",
    "    documents = load_documents_with_spans(directory_path, chunk_size=500, chunk_overlap=0)\n",
    "    print(f\"Loaded {len(documents)} document chunks with spans.\")\n",
    "\n",
    "    # Build the FAISS vector store using the list of Document objects.\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "    # Save the FAISS vector store locally for later retrieval.\n",
    "    vectorstore.save_local(vectorstore_path)\n",
    "    print(f\"FAISS vector store saved locally at '{vectorstore_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check 5 first samples\n",
    "loaded_vectorstore = FAISS.load_local(vectorstore_path, embeddings, allow_dangerous_deserialization=True)\n",
    "docstore_ids = dict(loaded_vectorstore.index_to_docstore_id)\n",
    "loaded_vectorstore.get_by_ids(list(docstore_ids.values())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DELETE A VECTOR STORE, RUN THIS CELL ##\n",
    "\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # Check if the directory exists\n",
    "# if os.path.exists(vectorstore_path):\n",
    "#     shutil.rmtree(vectorstore_path)\n",
    "#     print(f\"Deleted the FAISS vector store at: {vectorstore_path}\")\n",
    "# else:\n",
    "#     print(f\"No FAISS vector store found at: {vectorstore_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Rewriter (Simple Extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import difflib\n",
    "from collections import Counter\n",
    "from rapidfuzz import fuzz\n",
    "from typing import List, Tuple, Callable\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "def extract_tgt_corpus(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the target corpus description from the query and preprocesses it\n",
    "    by removing the term \"Non-Disclosure Agreement\" (case-insensitive) and common English stopwords.\n",
    "    \n",
    "    For example:\n",
    "      \"Consider the Non-Disclosure Agreement between Artop and Inno; Does the document permit...\"\n",
    "    returns (after preprocessing):\n",
    "      \"between Artop Inno\"\n",
    "    \"\"\"\n",
    "    # Extract text between \"Consider the \" and the first semicolon\n",
    "    pattern = r\"^Consider (.*?);\"\n",
    "    match = re.match(pattern, query)\n",
    "    if not match:\n",
    "        return \"\"\n",
    "    \n",
    "    tgt = match.group(1).strip()\n",
    "    \n",
    "    # Remove the term \"Non-Disclosure Agreement\" (case-insensitive)\n",
    "    tgt = re.sub(r\"(?i)Non-Disclosure Agreement\", \"\", tgt).strip()\n",
    "    \n",
    "    # Load common English stopwords from NLTK\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Tokenize the text (here using simple whitespace splitting)\n",
    "    tokens = tgt.split()\n",
    "    \n",
    "    # Filter out stopwords\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    processed_tgt = \" \".join(filtered_tokens)\n",
    "    return processed_tgt\n",
    "\n",
    "def find_best_corpus(tgt_corpus: str, corpus_files: List[str]) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Given a target corpus description and a list of corpus file names,\n",
    "    returns the file name with the highest similarity score and that score.\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_ratio = 0.0\n",
    "    for file in corpus_files:\n",
    "        ratio = difflib.SequenceMatcher(None, tgt_corpus.lower(), file.lower()).ratio()\n",
    "        if ratio > best_ratio:\n",
    "            best_ratio = ratio\n",
    "            best_match = file\n",
    "    return best_match, best_ratio\n",
    "\n",
    "def find_best_corpus_rapid(tgt_corpus: str, corpus_files: List[str]) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Uses RapidFuzz's token_set_ratio to compute a similarity score between the target corpus and each file name.\n",
    "    Returns the best matching file and its score (normalized between 0 and 1).\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0.0\n",
    "    for file in corpus_files:\n",
    "        # token_set_ratio handles unordered tokens and common token removal well.\n",
    "        score = fuzz.token_set_ratio(tgt_corpus, file)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = file\n",
    "    # Normalize the score to [0, 1] (RapidFuzz returns a value in [0,100])\n",
    "    return best_match, best_score / 100.0\n",
    "\n",
    "def find_best_corpus_embeddings(tgt_corpus: str, corpus_files: List[str],\n",
    "                                model: SentenceTransformer) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Embeds the target corpus description and each file name using a sentence transformer,\n",
    "    then computes cosine similarities to find the best matching file.\n",
    "    \"\"\"\n",
    "    # Embed the target description.\n",
    "    tgt_embedding = model.encode(tgt_corpus, convert_to_tensor=True)\n",
    "    # Embed all candidate file names.\n",
    "    file_embeddings = model.encode(corpus_files, convert_to_tensor=True)\n",
    "    # Compute cosine similarities.\n",
    "    cosine_scores = util.cos_sim(tgt_embedding, file_embeddings)[0]\n",
    "    # Get the index of the best matching file.\n",
    "    best_idx = int(cosine_scores.argmax())\n",
    "    best_score = float(cosine_scores[best_idx])\n",
    "    return corpus_files[best_idx], best_score\n",
    "\n",
    "\n",
    "def evaluate_corpus_matching(ground_truths: List[QAGroundTruth],\n",
    "                             candidate_files: List[str],\n",
    "                             threshold: float,\n",
    "                             match_fn: Callable[[str, List[str]], Tuple[str, float]]\n",
    "                             ) -> List[int]:\n",
    "    \"\"\"\n",
    "    For each QAGroundTruth:\n",
    "      - Extract the target corpus from the query.\n",
    "      - Find the best matching file using the provided match_fn and its similarity score.\n",
    "      - If the similarity score is below the threshold, assign a score of 0.\n",
    "      - If above the threshold:\n",
    "          * Assign 1 if the best matching file is among the actual file paths.\n",
    "          * Assign -1 if it does not match.\n",
    "    Returns a list of scores.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for gt in tqdm(ground_truths, desc=\"Evaluating queries\"):\n",
    "        tgt_corpus = extract_tgt_corpus(gt.query)\n",
    "        best_file, similarity = match_fn(tgt_corpus, candidate_files)\n",
    "        # Get the set of actual file paths from the ground truth snippets.\n",
    "        actual_files = {snippet.file_path for snippet in gt.snippets}\n",
    "        \n",
    "        if similarity >= threshold:\n",
    "            score = 1 if best_file in actual_files else -1\n",
    "        else:\n",
    "            score = 0\n",
    "\n",
    "        result = {\n",
    "            \"query\": gt.query,\n",
    "            \"targeted_corpus\": tgt_corpus,\n",
    "            \"best_file\": best_file,\n",
    "            \"similarity\": similarity,\n",
    "            \"actual_files\": list(actual_files),\n",
    "            \"score\": score\n",
    "        }\n",
    "        outputs.append(result)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "privacy_qa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating queries: 100%|██████████| 192/192 [00:03<00:00, 50.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  privacy_qa\n",
      "Final Score:  Counter({1: 192})\n",
      "privacy_qa_rephrased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating queries: 100%|██████████| 192/192 [00:03<00:00, 48.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  privacy_qa\n",
      "Final Score:  Counter({0: 192})\n",
      "privacy_qa_generic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating queries: 100%|██████████| 192/192 [00:04<00:00, 45.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  privacy_qa\n",
      "Final Score:  Counter({0: 192})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [\"\", \"rephrased\", \"generic\"]:\n",
    "    if t==\"rephrased\":\n",
    "        curr_file = rephrased_file\n",
    "        dataset_type = \"_rephrased\"\n",
    "    elif t==\"generic\":\n",
    "        curr_file = generic_file\n",
    "        dataset_type = \"_generic\"\n",
    "    else:\n",
    "        curr_file = test_file\n",
    "        dataset_type = \"\"\n",
    "\n",
    "    print(dataset_name+dataset_type)\n",
    "    groundtruth_tests = load_groundtruth(curr_file) # test_file, rephrased_file, generic_file\n",
    "    test_queries = [gt.query for gt in groundtruth_tests]\n",
    "    list_corpus = [os.path.join(f\"{dataset_name}\", filename) for filename in os.listdir(directory_path) if filename.endswith(\".txt\")]\n",
    "\n",
    "    threshold = 0.3\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    match_fn_embeddings = lambda tgt, files: find_best_corpus_embeddings(tgt, files, model)\n",
    "\n",
    "    results = evaluate_corpus_matching(groundtruth_tests, list_corpus, threshold, match_fn_embeddings)\n",
    "\n",
    "    with open(f\"../data/results/query_rewriter/SE_{dataset_name}{dataset_type}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    # for sample in random.sample(results, 5):\n",
    "    #     print(json.dumps(sample, indent=2))\n",
    "\n",
    "    scores = [results[i][\"score\"] for i in range(len(results))]\n",
    "    counts = Counter(scores)\n",
    "    print(\"dataset: \", dataset_name)\n",
    "    print(\"Final Score: \", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_tests = load_groundtruth(generic_file) # test_file, rephrased_file, generic_file\n",
    "test_queries = [gt.query for gt in groundtruth_tests]\n",
    "list_corpus = [os.path.join(f\"{dataset_name}\", filename) for filename in os.listdir(directory_path) if filename.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating queries: 100%|██████████| 194/194 [00:06<00:00, 30.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"In legal or contractual agreements, is it typically permissible for the Receiving Party to disclose certain Confidential Information to their employees?\",\n",
      "  \"targeted_corpus\": \"\",\n",
      "  \"best_file\": \"contractnli/HNBA-2017-18-Confidentiality-Agreement.txt\",\n",
      "  \"similarity\": 0.14289790391921997,\n",
      "  \"actual_files\": [\n",
      "    \"contractnli/Data Use Agreement New York City.txt\"\n",
      "  ],\n",
      "  \"score\": 0\n",
      "}\n",
      "{\n",
      "  \"query\": \"In confidentiality agreements, is it typically specified whether the Receiving Party must inform the Disclosing Party if legal or regulatory obligations necessitate the disclosure of Confidential Information?\",\n",
      "  \"targeted_corpus\": \"\",\n",
      "  \"best_file\": \"contractnli/HNBA-2017-18-Confidentiality-Agreement.txt\",\n",
      "  \"similarity\": 0.14289790391921997,\n",
      "  \"actual_files\": [\n",
      "    \"contractnli/HNBA-2017-18-Confidentiality-Agreement.txt\"\n",
      "  ],\n",
      "  \"score\": 0\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"Typically, do Non-Disclosure Agreements permit the Receiving Party to disclose certain Confidential Information to third parties such as consultants, agents, and professional advisors?\\\"\",\n",
      "  \"targeted_corpus\": \"\",\n",
      "  \"best_file\": \"contractnli/HNBA-2017-18-Confidentiality-Agreement.txt\",\n",
      "  \"similarity\": 0.14289790391921997,\n",
      "  \"actual_files\": [\n",
      "    \"contractnli/ExcelerateStandardNDAFormat.txt\"\n",
      "  ],\n",
      "  \"score\": 0\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"Would a typical Non-Disclosure Agreement permit the Receiving Party to obtain information resembling the Confidential Information from an external source?\\\"\",\n",
      "  \"targeted_corpus\": \"\",\n",
      "  \"best_file\": \"contractnli/HNBA-2017-18-Confidentiality-Agreement.txt\",\n",
      "  \"similarity\": 0.14289790391921997,\n",
      "  \"actual_files\": [\n",
      "    \"contractnli/INFOMAGNET%20NDA.txt\"\n",
      "  ],\n",
      "  \"score\": 0\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"Are parties usually obligated to inform each other in legal situations where disclosure of Confidential Information is mandated by law in Non-Disclosure Agreements?\\\"\",\n",
      "  \"targeted_corpus\": \"\",\n",
      "  \"best_file\": \"contractnli/HNBA-2017-18-Confidentiality-Agreement.txt\",\n",
      "  \"similarity\": 0.14289790391921997,\n",
      "  \"actual_files\": [\n",
      "    \"contractnli/IBC-PMS-NDA-agreement.txt\"\n",
      "  ],\n",
      "  \"score\": 0\n",
      "}\n",
      "dataset:  contractnli\n",
      "Final Score:  Counter({0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "match_fn_embeddings = lambda tgt, files: find_best_corpus_embeddings(tgt, files, model)\n",
    "\n",
    "results = evaluate_corpus_matching(groundtruth_tests, list_corpus, threshold, match_fn_embeddings)\n",
    "\n",
    "for sample in random.sample(results, 5):\n",
    "    print(json.dumps(sample, indent=2))\n",
    "\n",
    "with open(f\"../data/results/query_rewriter/SE_{dataset_name}_generic.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "scores = [results[i][\"score\"] for i in range(len(results))]\n",
    "counts = Counter(scores)\n",
    "print(\"dataset: \", dataset_name)\n",
    "print(\"Final Score: \", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Rewriter (Small Language Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/figarrikeisha/.virtualenvs/nlpenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import difflib\n",
    "from collections import Counter\n",
    "from rapidfuzz import fuzz\n",
    "from typing import List, Tuple, Callable\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "def split_question(query: str, model) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Splits a query into two parts using a language model with few-shot prompt engineering.\n",
    "    \n",
    "    The function identifies:\n",
    "      - targeted_corpus: a concise phrase that identifies the relevant document or agreement (e.g., \"Evelozcity's Non-Disclosure Agreement\" or \"EFCA's Non-Disclosure Agreement\").\n",
    "      - original_question: the actual question about that document.\n",
    "    \n",
    "    The prompt provides examples for both semicolon-separated queries and naturally phrased queries.\n",
    "    Output is expected as a JSON object with keys 'targeted_corpus' and 'original_question'.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Split the following query into two parts and output a JSON object with keys 'targeted_corpus' and 'original_question'.\\n\"\n",
    "        \"The targeted_corpus should be a short phrase describing the document or agreement being referenced, and the original_question should be the question part.\\n\\n\"\n",
    "        \"Example 1 (semicolon-delimited):\\n\"\n",
    "        \"Input: \\\"Consider the Non-Disclosure Agreement between CopAcc and ToP Mentors; Does the document indicate that the Agreement does not grant any rights to the Confidential Information?\\\"\\n\"\n",
    "        \"Output: {\\\"targeted_corpus\\\": \\\"CopAcc and ToP Mentors\\\", \\\"original_question\\\": \\\"Does the document indicate that the Agreement does not grant any rights to the Confidential Information?\\\"}\\n\\n\"\n",
    "        \"Example 2 (natural language):\\n\"\n",
    "        \"Input: \\\"Is the Confidential Information covered in Evelozcity's Non-Disclosure Agreement? Are there any specific examples of technical information that is covered?\\\"\\n\"\n",
    "        \"Output: {\\\"targeted_corpus\\\": \\\"Evelozcity\\\", \\\"original_question\\\": \\\"Does the document state that Confidential Information shall only include technical information?\\\"}\\n\\n\"\n",
    "        \"Example 3 (another natural language example):\\n\"\n",
    "        \"Input: \\\"Does the Data Use Agreement in New York City specify if the Receiving Party must return or destroy Confidential Information upon termination?\\\"\\n\"\n",
    "        \"Output: {\\\"targeted_corpus\\\": \\\"Data Use Agreement in New York City\\\", \\\"original_question\\\": \\\"Does the Data Use Agreement in New York City specify if the Receiving Party must return or destroy Confidential Information upon termination?\\\"}\\n\\n\"\n",
    "        \"Now, split the following query:\\n\"\n",
    "        f\"Input: \\\"{query}\\\"\\n\\n\"\n",
    "        \"Output:\"\n",
    "    )\n",
    "    \n",
    "    # Increase max_new_tokens to allow a longer answer and use sampling.\n",
    "    output = model(prompt, max_new_tokens=250, do_sample=True, temperature=0.5)\n",
    "    generated_text = output[0]['generated_text'].strip()\n",
    "    \n",
    "    # Debug print (optional):\n",
    "    # print(\"Raw generated text:\", generated_text)\n",
    "    \n",
    "    # If the generated text does not start with a curly brace, add them.\n",
    "    if not generated_text.startswith(\"{\"):\n",
    "        # Try to extract the JSON-like part using regex (optional improvement).\n",
    "        json_like = re.search(r\"\\{.*\\}\", generated_text, re.DOTALL)\n",
    "        if json_like:\n",
    "            generated_text = json_like.group(0)\n",
    "        else:\n",
    "            generated_text = \"{\" + generated_text + \"}\"\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(generated_text)\n",
    "        targeted_corpus = result.get(\"targeted_corpus\", \"\").strip()\n",
    "        original_question = result.get(\"original_question\", \"\").strip()\n",
    "    except Exception as e:\n",
    "        # Fallback: if JSON parsing fails, fall back to a heuristic split on the semicolon.\n",
    "        parts = query.split(\";\", 1)\n",
    "        targeted_corpus = parts[0].replace(\"Consider\", \"\").strip() if parts else \"\"\n",
    "        original_question = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "    \n",
    "    return targeted_corpus, original_question\n",
    "\n",
    "def find_best_corpus(tgt_corpus: str, corpus_files: List[str]) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Given a target corpus description and a list of corpus file names,\n",
    "    returns the file name with the highest similarity score and that score.\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_ratio = 0.0\n",
    "    for file in corpus_files:\n",
    "        ratio = difflib.SequenceMatcher(None, tgt_corpus.lower(), file.lower()).ratio()\n",
    "        if ratio > best_ratio:\n",
    "            best_ratio = ratio\n",
    "            best_match = file\n",
    "    return best_match, best_ratio\n",
    "\n",
    "def find_best_corpus_rapid(tgt_corpus: str, corpus_files: List[str]) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Uses RapidFuzz's token_set_ratio to compute a similarity score between the target corpus and each file name.\n",
    "    Returns the best matching file and its score (normalized between 0 and 1).\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0.0\n",
    "    for file in corpus_files:\n",
    "        # token_set_ratio handles unordered tokens and common token removal well.\n",
    "        score = fuzz.token_set_ratio(tgt_corpus, file)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = file\n",
    "    # Normalize the score to [0, 1] (RapidFuzz returns a value in [0,100])\n",
    "    return best_match, best_score / 100.0\n",
    "\n",
    "def find_best_corpus_embeddings(tgt_corpus: str, corpus_files: List[str],\n",
    "                                model: SentenceTransformer) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Embeds the target corpus description and each file name using a sentence transformer,\n",
    "    then computes cosine similarities to find the best matching file.\n",
    "    \"\"\"\n",
    "    # Embed the target description.\n",
    "    tgt_embedding = model.encode(tgt_corpus, convert_to_tensor=True)\n",
    "    # Embed all candidate file names.\n",
    "    file_embeddings = model.encode(corpus_files, convert_to_tensor=True)\n",
    "    # Compute cosine similarities.\n",
    "    cosine_scores = util.cos_sim(tgt_embedding, file_embeddings)[0]\n",
    "    # Get the index of the best matching file.\n",
    "    best_idx = int(cosine_scores.argmax())\n",
    "    best_score = float(cosine_scores[best_idx])\n",
    "    return corpus_files[best_idx], best_score\n",
    "\n",
    "\n",
    "def evaluate_corpus_matching(ground_truths: List[QAGroundTruth],\n",
    "                             candidate_files: List[str],\n",
    "                             threshold: float,\n",
    "                             match_fn: Callable[[str, List[str]], Tuple[str, float]]\n",
    "                             ) -> List[int]:\n",
    "    \"\"\"\n",
    "    For each QAGroundTruth:\n",
    "      - Extract the target corpus from the query.\n",
    "      - Find the best matching file using the provided match_fn and its similarity score.\n",
    "      - If the similarity score is below the threshold, assign a score of 0.\n",
    "      - If above the threshold:\n",
    "          * Assign 1 if the best matching file is among the actual file paths.\n",
    "          * Assign -1 if it does not match.\n",
    "    Returns a list of scores.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "    for gt in tqdm(ground_truths, desc=\"Evaluating queries\"):\n",
    "        tgt_corpus, orig = split_question(gt.query, model)\n",
    "        best_file, similarity = match_fn(tgt_corpus, candidate_files)\n",
    "        # Get the set of actual file paths from the ground truth snippets.\n",
    "        actual_files = {snippet.file_path for snippet in gt.snippets}\n",
    "        \n",
    "        if similarity >= threshold:\n",
    "            score = 1 if best_file in actual_files else -1\n",
    "        else:\n",
    "            score = 0\n",
    "\n",
    "        result = {\n",
    "            \"query\": gt.query,\n",
    "            \"targeted_corpus\": tgt_corpus,\n",
    "            \"best_file\": best_file,\n",
    "            \"similarity\": similarity,\n",
    "            \"actual_files\": list(actual_files),\n",
    "            \"score\": score\n",
    "        }\n",
    "        outputs.append(result)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rephrased_file = f\"../data/{'sample_' if _use_sample else ''}benchmarks/{dataset_name}_rephrased_split_2.json\"\n",
    "groundtruth_tests = load_groundtruth(rephrased_file) # test_file, rephrased_file\n",
    "test_queries = [gt.query for gt in groundtruth_tests]\n",
    "list_corpus = [os.path.join(f\"{dataset_name}\", filename) for filename in os.listdir(directory_path) if filename.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Evaluating queries: 100%|██████████| 60/60 [07:27<00:00,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"\\\"Consider DBT's Mutual Non-Disclosure Agreement; Does the document include a clause that prevents the Receiving Party from disclosing the fact that the Agreement was agreed upon or negotiated?\\\"\",\n",
      "  \"targeted_corpus\": \"DBT's Mutual Non-Disclosure Agreement; Does the document include a clause that prevents the Receiving Party from disclosing the fact that the Agreement was agreed upon or negotiated?\",\n",
      "  \"best_file\": \"contractnli/IGC-Non-Disclosure-Agreement-LSE-Sample.txt\",\n",
      "  \"similarity\": 0.5515354871749878,\n",
      "  \"actual_files\": [\n",
      "    \"contractnli/DBT%20Mutual%20NDA.txt\"\n",
      "  ],\n",
      "  \"score\": -1\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"In the Non-Disclosure Agreement between IGC and LSE, does the document mention whether certain obligations continue even after the Agreement is terminated?\\\"\",\n",
      "  \"targeted_corpus\": \"\\\"In the Non-Disclosure Agreement between IGC and LSE, does the document mention whether certain obligations continue even after the Agreement is terminated?\\\"\",\n",
      "  \"best_file\": \"contractnli/IGC-Non-Disclosure-Agreement-LSE-Sample.txt\",\n",
      "  \"similarity\": 0.6690535545349121,\n",
      "  \"actual_files\": [\n",
      "    \"contractnli/IGC-Non-Disclosure-Agreement-LSE-Sample.txt\"\n",
      "  ],\n",
      "  \"score\": 1\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"Consider the Non-Disclosure Agreement between Hochschule Furtwangen University and Thesis Participants; Does the document allow the Receiving Party to share some Confidential Information with third parties, including consultants, agents, and professional advisors??\\\"\",\n",
      "  \"targeted_corpus\": \"\\\" the Non-Disclosure Agreement between Hochschule Furtwangen University and Thesis Participants\",\n",
      "  \"best_file\": \"contractnli/IGC-Non-Disclosure-Agreement-LSE-Sample.txt\",\n",
      "  \"similarity\": 0.4437294006347656,\n",
      "  \"actual_files\": [\n",
      "    \"contractnli/Geheimhaltungsvereinbarung_Abschlussarbeiten_HFU_englisch.txt\"\n",
      "  ],\n",
      "  \"score\": -1\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"In APIC's Confidentiality Agreement, what is the statement that the Confidential Information shall include?\",\n",
      "  \"targeted_corpus\": \"APIC's Confidentiality Agreement\",\n",
      "  \"best_file\": \"contractnli/Focus-Group-APIC-Seattle-Confidentiality-Agreement-031115.txt\",\n",
      "  \"similarity\": 0.6528750658035278,\n",
      "  \"actual_files\": [\n",
      "    \"contractnli/Focus-Group-APIC-Seattle-Confidentiality-Agreement-031115.txt\"\n",
      "  ],\n",
      "  \"score\": 1\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"Does HNBA's Confidentiality Agreement restrict the use of Confidential Information to the purposes stated in the Agreement?\\\"\",\n",
      "  \"targeted_corpus\": \"HNBA's Confidentiality Agreement\",\n",
      "  \"best_file\": \"contractnli/HNBA-2017-18-Confidentiality-Agreement.txt\",\n",
      "  \"similarity\": 0.7620667219161987,\n",
      "  \"actual_files\": [\n",
      "    \"contractnli/HNBA-2017-18-Confidentiality-Agreement.txt\"\n",
      "  ],\n",
      "  \"score\": 1\n",
      "}\n",
      "dataset:  contractnli\n",
      "Final Score:  Counter({1: 36, -1: 21, 0: 3})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "match_fn_embeddings = lambda tgt, files: find_best_corpus_embeddings(tgt, files, model)\n",
    "\n",
    "results = evaluate_corpus_matching(groundtruth_tests, list_corpus, threshold, match_fn_embeddings)\n",
    "\n",
    "for sample in random.sample(results, 5):\n",
    "    print(json.dumps(sample, indent=2))\n",
    "\n",
    "scores = [results[i][\"score\"] for i in range(len(results))]\n",
    "counts = Counter(scores)\n",
    "print(\"dataset: \", dataset_name)\n",
    "print(\"Final Score: \", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Rewriter (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Callable, Dict\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "def compute_query_complexity() -> Tuple[str, int]:\n",
    "    \"\"\"\n",
    "    Instead of computing complexity based on the query length, this function\n",
    "    randomly returns one of the following pairs:\n",
    "      - (\"simple\", 1)\n",
    "      - (\"intermediate\", 3)\n",
    "      - (\"complex\", 5)\n",
    "    \"\"\"\n",
    "    options = [(\"simple\", 1), (\"intermediate\", 3), (\"complex\", 5)]\n",
    "    return random.choice(options)\n",
    "\n",
    "def split_question_ner(query: str, ner_model) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Splits a query into two parts using Named Entity Recognition.\n",
    "    \n",
    "    If the query contains a semicolon, it uses that to split into:\n",
    "      - targeted_corpus: the text before the semicolon (after removing \"Consider\")\n",
    "      - original_question: the text after the semicolon.\n",
    "      \n",
    "    Otherwise, it uses the provided NER pipeline to extract an organization or miscellaneous entity \n",
    "    (e.g. an agreement or company name) from the query as the targeted corpus.\n",
    "    The remainder of the query (with the extracted entity removed) is taken as the original question.\n",
    "    \n",
    "    Example:\n",
    "      Input: \"Is the Confidential Information covered in Evelozcity's Non-Disclosure Agreement? Are there any specific examples of technical information that is covered?\"\n",
    "      Might yield: (\"Evelozcity\", \"Is the Confidential Information covered? Are there any specific examples of technical information that is covered?\")\n",
    "    \"\"\"\n",
    "\n",
    "    unwanted_words = ['agreement', 'nda', 'non-disclosure', 'agreements', 'content', 'co-branding', 'license', \"acquisition\", \"merger\"]\n",
    "    pattern = r\"^Consider (.*?);\"\n",
    "    match = re.match(pattern, query)\n",
    "    if match:\n",
    "        tgt = match.group(1).strip()\n",
    "        # Remove the term \"Non-Disclosure Agreement\" (case-insensitive)\n",
    "        tgt = re.sub(r\"(?i)Non-Disclosure Agreement\", \"\", tgt).strip()\n",
    "        # Load common English stopwords from NLTK\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        stop_words.update()\n",
    "        # Tokenize the text (here using simple whitespace splitting)\n",
    "        tokens = tgt.split()\n",
    "        # Filter out stopwords\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "        # Join tokens back into a string\n",
    "        targeted_corpus = \" \".join(filtered_tokens)\n",
    "        # Define original question\n",
    "        parts = query.split(\";\", 1)\n",
    "        original_question = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "        return targeted_corpus, original_question\n",
    "\n",
    "    else:\n",
    "        # Use NER to extract an entity (e.g., organization) as the targeted corpus.\n",
    "        ner_results = ner_model(query)\n",
    "        # Filter for entities with label ORG.\n",
    "        org_entities = [ent[\"word\"].strip().lower() for ent in ner_results if ent.get(\"entity_group\") in [\"ORG\", \"MISC\"] and ent.get(\"score\") > 0.8]\n",
    "        # Compile a regex that matches any of the unwanted words as whole words (case-insensitive).\n",
    "        pattern = re.compile(r\"\\b(\" + \"|\".join(unwanted_words) + r\")\\b\", re.IGNORECASE)\n",
    "        # For each entity, remove the unwanted words and then filter out any empty results.\n",
    "        filtered_orgs = [pattern.sub(\"\", org).strip() for org in org_entities]\n",
    "        filtered_orgs = [org for org in filtered_orgs if org]\n",
    "        \n",
    "        if filtered_orgs:\n",
    "            targeted_corpus = \" \".join(filtered_orgs)\n",
    "        else:\n",
    "            targeted_corpus = \"\"\n",
    "    \n",
    "    # Remove the targeted_corpus from the query to form the original question.\n",
    "    original_question = query.replace(targeted_corpus, \"\").strip()\n",
    "    return targeted_corpus, original_question\n",
    "    \n",
    "def find_best_corpus_embeddings(tgt_corpus: str, corpus_files: List[str],\n",
    "                                model: SentenceTransformer) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Embeds the target corpus description and each file name using a sentence transformer,\n",
    "    then computes cosine similarities to find the best matching file.\n",
    "    \"\"\"\n",
    "    # Embed the target description.\n",
    "    tgt_embedding = model.encode(tgt_corpus, convert_to_tensor=True)\n",
    "    # Embed all candidate file names.\n",
    "    file_embeddings = model.encode(corpus_files, convert_to_tensor=True)\n",
    "    # Compute cosine similarities.\n",
    "    cosine_scores = util.cos_sim(tgt_embedding, file_embeddings)[0]\n",
    "    # Get the index of the best matching file.\n",
    "    best_idx = int(cosine_scores.argmax())\n",
    "    best_score = float(cosine_scores[best_idx])\n",
    "    return corpus_files[best_idx], best_score\n",
    "\n",
    "def evaluate_corpus_matching(ground_truths: List[QAGroundTruth],\n",
    "                             candidate_files: List[str],\n",
    "                             threshold: float,\n",
    "                             match_fn: Callable[[str, List[str]], Tuple[str, float]],\n",
    "                             split_fn: Callable[[str], Tuple[str, str]]\n",
    "                             ) -> List[dict]:\n",
    "    \"\"\"\n",
    "    For each QAGroundTruth:\n",
    "      - Splits the query into targeted_corpus and original_question using split_fn.\n",
    "      - Finds the best matching file using the provided match_fn and its similarity score.\n",
    "      - If the similarity score is below the threshold, assigns a score of 0.\n",
    "      - If above the threshold:\n",
    "          * Assigns 1 if the best matching file is among the actual file paths.\n",
    "          * Assigns -1 if it does not match.\n",
    "    \n",
    "    Returns a list of dictionaries with the following keys:\n",
    "      - \"query\", \"targeted_corpus\", \"best_file\", \"similarity\", \"actual_files\", and \"score\".\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for gt in tqdm(ground_truths, desc=\"Evaluating queries\"):\n",
    "        targeted_corpus, _ = split_fn(gt.query)\n",
    "        best_file, similarity = match_fn(targeted_corpus, candidate_files)\n",
    "        actual_files = {snippet.file_path for snippet in gt.snippets}\n",
    "        \n",
    "        if similarity >= threshold:\n",
    "            score = 1 if best_file in actual_files else -1\n",
    "        else:\n",
    "            score = 0\n",
    "        \n",
    "        result = {\n",
    "            \"query\": gt.query,\n",
    "            \"targeted_corpus\": targeted_corpus,\n",
    "            \"best_file\": best_file,\n",
    "            \"similarity\": similarity,\n",
    "            \"actual_files\": list(actual_files),\n",
    "            \"score\": score\n",
    "        }\n",
    "        outputs.append(result)\n",
    "    return outputs\n",
    "\n",
    "def query_rewriter(\n",
    "    ground_truths: List[QAGroundTruth],\n",
    "    candidate_files: List[str],\n",
    "    threshold: float,\n",
    "    match_fn: Callable[[str, List[str]], Tuple[str, float]],\n",
    "    split_fn: Callable[[str], Tuple[str, str]]\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    For each QAGroundTruth:\n",
    "      - Splits the query using split_fn into:\n",
    "          * targeted_corpus (the extracted document or agreement details)\n",
    "          * only_question (the actual question about that document)\n",
    "      - Finds the best matching file using match_fn and its similarity score.\n",
    "      - Computes a simple query complexity metric and corresponding retrieved_k value.\n",
    "      - Determines a score:\n",
    "            * If similarity >= threshold: score is 1 if best_file is among the ground truth's actual file paths, else -1.\n",
    "            * Otherwise, score is 0.\n",
    "    \n",
    "    Returns a list of dictionaries in the new format with keys:\n",
    "      - \"query\", \"snippets\", \"file_set\" (if available),\n",
    "      - \"query_rewriter\": a list with a dictionary containing:\n",
    "            \"best_file_path\", \"file_locator\", \"similarity_score\", \"only_question\"\n",
    "      - \"feature_extraction\": a list with a dictionary containing:\n",
    "            \"query_complexity\", \"retrieved_k\"\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for gt in tqdm(ground_truths, desc=\"Evaluating queries\"):\n",
    "        targeted_corpus, only_question = split_fn(gt.query)\n",
    "        best_file, similarity = match_fn(targeted_corpus, candidate_files)\n",
    "        \n",
    "        if similarity >= threshold:\n",
    "            query_rewriter_value = {\n",
    "                \"best_file_path\": best_file,\n",
    "                \"file_locator\": targeted_corpus,\n",
    "                \"similarity_score\": similarity,\n",
    "                \"only_question\": only_question\n",
    "            }\n",
    "        else:\n",
    "            query_rewriter_value = {\n",
    "                \"best_file_path\": \"\",\n",
    "                \"file_locator\": targeted_corpus,\n",
    "                \"similarity_score\": similarity,\n",
    "                \"only_question\": \"\"\n",
    "            }\n",
    "        \n",
    "        # Compute query complexity based on the full query (or you may choose only_question).\n",
    "        complexity, retrieved_k = compute_query_complexity()\n",
    "        \n",
    "        result = {\n",
    "            \"query\": gt.query,\n",
    "            \"snippets\": [snippet.dict() for snippet in gt.snippets],\n",
    "            \"file_set\": gt.file_set if gt.file_set is not None else [],\n",
    "            \"query_rewriter\": [query_rewriter_value],\n",
    "            \"feature_extraction\": [\n",
    "                {\n",
    "                    \"query_complexity\": complexity,\n",
    "                    \"retrieved_k\": retrieved_k\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "        outputs.append(result)\n",
    "    return outputs\n",
    "\n",
    "def save_evaluation_results(results: List[dict], output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the evaluation results (a list of dictionaries) to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "      results: The list of result dictionaries.\n",
    "      output_file: The path to the output JSON file.\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"Saved evaluation results to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "privacy_qa_generic\n"
     ]
    }
   ],
   "source": [
    "curr_file = generic_file\n",
    "\n",
    "if \"rephrased\" in curr_file:\n",
    "    dataset_type = \"_rephrased\"\n",
    "elif \"generic\" in curr_file:\n",
    "    dataset_type = \"_generic\"\n",
    "else:\n",
    "    dataset_type = \"\"\n",
    "\n",
    "print(dataset_name+dataset_type)\n",
    "groundtruth_tests = load_groundtruth(curr_file) # test_file, rephrased_file, generic_file\n",
    "test_queries = [gt.query for gt in groundtruth_tests]\n",
    "list_corpus = [os.path.join(f\"{dataset_name}\", filename) for filename in os.listdir(directory_path) if filename.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Evaluating queries: 100%|██████████| 192/192 [00:10<00:00, 17.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"\\\"What are the typical practices regarding the handling of DNA information as outlined in privacy policies?\\\"\",\n",
      "  \"targeted_corpus\": \"dna\",\n",
      "  \"best_file\": \"privacy_qa/23andMe.txt\",\n",
      "  \"similarity\": 0.1454026997089386,\n",
      "  \"actual_files\": [\n",
      "    \"privacy_qa/23andMe.txt\"\n",
      "  ],\n",
      "  \"score\": 0\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"Can privacy policies typically request access to location services even when they are not actively being used?\\\"\",\n",
      "  \"targeted_corpus\": \"\",\n",
      "  \"best_file\": \"privacy_qa/Wordscapes.txt\",\n",
      "  \"similarity\": 0.09173782914876938,\n",
      "  \"actual_files\": [\n",
      "    \"privacy_qa/Groupon.txt\"\n",
      "  ],\n",
      "  \"score\": 0\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"Does the privacy policy of platforms typically address concerns about the visibility of personal information to other users?\\\"\",\n",
      "  \"targeted_corpus\": \"\",\n",
      "  \"best_file\": \"privacy_qa/Wordscapes.txt\",\n",
      "  \"similarity\": 0.09173782914876938,\n",
      "  \"actual_files\": [\n",
      "    \"privacy_qa/Groupon.txt\"\n",
      "  ],\n",
      "  \"score\": 0\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"Does the privacy policy of a typical service provider include provisions regarding the sharing of user data with third parties?\\\"\",\n",
      "  \"targeted_corpus\": \"\",\n",
      "  \"best_file\": \"privacy_qa/Wordscapes.txt\",\n",
      "  \"similarity\": 0.09173782914876938,\n",
      "  \"actual_files\": [\n",
      "    \"privacy_qa/TickTick: To Do List with Reminder, Day Planner.txt\"\n",
      "  ],\n",
      "  \"score\": 0\n",
      "}\n",
      "{\n",
      "  \"query\": \"\\\"Does the privacy policy of task management applications typically address the storage of reminder data?\\\"\",\n",
      "  \"targeted_corpus\": \"\",\n",
      "  \"best_file\": \"privacy_qa/Wordscapes.txt\",\n",
      "  \"similarity\": 0.09173782914876938,\n",
      "  \"actual_files\": [\n",
      "    \"privacy_qa/TickTick: To Do List with Reminder, Day Planner.txt\"\n",
      "  ],\n",
      "  \"score\": 0\n",
      "}\n",
      "dataset:  privacy_qa\n",
      "Final Score:  Counter({0: 166, 1: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "match_fn_embeddings = lambda tgt, files: find_best_corpus_embeddings(tgt, files, model)\n",
    "\n",
    "# Define the split function to use NER.\n",
    "# Jean-Baptiste/roberta-large-ner-english\n",
    "# dbmdz/bert-large-casedz-finetuned-conll03-english\n",
    "ner_model = pipeline(\"ner\", model=\"Jean-Baptiste/roberta-large-ner-english\", aggregation_strategy=\"simple\")\n",
    "split_fn = lambda query: split_question_ner(query, ner_model)\n",
    "\n",
    "results = evaluate_corpus_matching(groundtruth_tests, list_corpus, threshold, match_fn_embeddings, split_fn)\n",
    "\n",
    "with open(f\"../data/results/query_rewriter/NER_{dataset_name}{dataset_type}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "for sample in random.sample(results, 5):\n",
    "    print(json.dumps(sample, indent=2))\n",
    "\n",
    "scores = [results[i][\"score\"] for i in range(len(results))]\n",
    "counts = Counter(scores)\n",
    "print(\"dataset: \", dataset_name)\n",
    "print(\"Final Score: \", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Evaluating queries:   0%|          | 0/192 [00:00<?, ?it/s]/var/folders/hk/j9r7jggx4dxgt8gmzj_c2z080000gn/T/ipykernel_80283/1663387140.py:187: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  \"snippets\": [snippet.dict() for snippet in gt.snippets],\n",
      "Evaluating queries: 100%|██████████| 192/192 [00:05<00:00, 37.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"Consider \\\"Fiverr\\\"'s privacy policy; who can see the jobs that i post?\",\n",
      "  \"snippets\": [\n",
      "    {\n",
      "      \"file_path\": \"privacy_qa/Fiverr.txt\",\n",
      "      \"span\": [\n",
      "        3969,\n",
      "        4312\n",
      "      ],\n",
      "      \"answer\": \"In other words, when you access the Site we are aware of your usage of the Site, and may gather, collect and record the information relating to such usage, including geo-location information, IP address, device and connection information, browser information and web-log information, and all communications recorded by Users through the Site.\\n\"\n",
      "    }\n",
      "  ],\n",
      "  \"file_set\": [\n",
      "    \"Fiverr.txt\"\n",
      "  ],\n",
      "  \"query_rewriter\": [\n",
      "    {\n",
      "      \"best_file_path\": \"privacy_qa/Fiverr.txt\",\n",
      "      \"file_locator\": \"\\\"Fiverr\\\"'s privacy policy\",\n",
      "      \"similarity_score\": 0.6958917379379272,\n",
      "      \"only_question\": \"who can see the jobs that i post?\"\n",
      "    }\n",
      "  ],\n",
      "  \"feature_extraction\": [\n",
      "    {\n",
      "      \"query_complexity\": \"intermediate\",\n",
      "      \"retrieved_k\": 3\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"query\": \"Consider \\\"Groupon\\\"'s privacy policy; is my data safe\",\n",
      "  \"snippets\": [\n",
      "    {\n",
      "      \"file_path\": \"privacy_qa/Groupon.txt\",\n",
      "      \"span\": [\n",
      "        13561,\n",
      "        14100\n",
      "      ],\n",
      "      \"answer\": \"Groupon has implemented an information security program that contains administrative, technical and physical controls that are designed to reasonably safeguardPersonal Information.\\nFor example, we use industry-standard encryption technology to secureFinancial Account Information.\\nNo method of transmission over the Internet, or method of electronic storage, is 100% secure, however.\\nTherefore, we cannot guarantee its absolute security.\\nIf you have any questions about security on our Web site, you can contact us at privacy@groupon.com.\\n\"\n",
      "    }\n",
      "  ],\n",
      "  \"file_set\": [\n",
      "    \"Groupon.txt\"\n",
      "  ],\n",
      "  \"query_rewriter\": [\n",
      "    {\n",
      "      \"best_file_path\": \"privacy_qa/Groupon.txt\",\n",
      "      \"file_locator\": \"\\\"Groupon\\\"'s privacy policy\",\n",
      "      \"similarity_score\": 0.654893159866333,\n",
      "      \"only_question\": \"is my data safe\"\n",
      "    }\n",
      "  ],\n",
      "  \"feature_extraction\": [\n",
      "    {\n",
      "      \"query_complexity\": \"complex\",\n",
      "      \"retrieved_k\": 5\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"query\": \"Consider \\\"Viber Messenger\\\"'s privacy policy; who will be able to see my information and/or the messages that i send?\",\n",
      "  \"snippets\": [\n",
      "    {\n",
      "      \"file_path\": \"privacy_qa/Viber Messenger.txt\",\n",
      "      \"span\": [\n",
      "        500,\n",
      "        773\n",
      "      ],\n",
      "      \"answer\": \"First of all, we want you to be assured that we do not read or listen to the content of your messages and/or calls made privately via Viber and we do not store those messages once they have been delivered to their destination (which on average takes less than one second).\\n\"\n",
      "    }\n",
      "  ],\n",
      "  \"file_set\": [\n",
      "    \"Viber Messenger.txt\"\n",
      "  ],\n",
      "  \"query_rewriter\": [\n",
      "    {\n",
      "      \"best_file_path\": \"privacy_qa/Viber Messenger.txt\",\n",
      "      \"file_locator\": \"\\\"Viber Messenger\\\"'s privacy policy\",\n",
      "      \"similarity_score\": 0.7511272430419922,\n",
      "      \"only_question\": \"who will be able to see my information and/or the messages that i send?\"\n",
      "    }\n",
      "  ],\n",
      "  \"feature_extraction\": [\n",
      "    {\n",
      "      \"query_complexity\": \"simple\",\n",
      "      \"retrieved_k\": 1\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"query\": \"Consider \\\"23andMe\\\"'s privacy policy; is the information encrypted\",\n",
      "  \"snippets\": [\n",
      "    {\n",
      "      \"file_path\": \"privacy_qa/23andMe.txt\",\n",
      "      \"span\": [\n",
      "        37854,\n",
      "        37965\n",
      "      ],\n",
      "      \"answer\": \"23andMe uses industry standard security measures to encrypt Sensitive Information both at rest and in transit.\\n\"\n",
      "    }\n",
      "  ],\n",
      "  \"file_set\": [\n",
      "    \"23andMe.txt\"\n",
      "  ],\n",
      "  \"query_rewriter\": [\n",
      "    {\n",
      "      \"best_file_path\": \"privacy_qa/23andMe.txt\",\n",
      "      \"file_locator\": \"\\\"23andMe\\\"'s privacy policy\",\n",
      "      \"similarity_score\": 0.6163405179977417,\n",
      "      \"only_question\": \"is the information encrypted\"\n",
      "    }\n",
      "  ],\n",
      "  \"feature_extraction\": [\n",
      "    {\n",
      "      \"query_complexity\": \"complex\",\n",
      "      \"retrieved_k\": 5\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"query\": \"Consider \\\"Wordscapes\\\"'s privacy policy; does it collect payment information\",\n",
      "  \"snippets\": [\n",
      "    {\n",
      "      \"file_path\": \"privacy_qa/Wordscapes.txt\",\n",
      "      \"span\": [\n",
      "        3430,\n",
      "        3913\n",
      "      ],\n",
      "      \"answer\": \"When you order any good or service through the Game, including any virtual currency or virtual good, our payment processing service provider will collect your name, phone number, e-mail address, mailing address, billing address, and complete credit card information that enables them to receive your payment.\\nOur payment processing service provider may also retain this information to enable you to purchase additional items through our Game without having to re-enter it each time.\\n\"\n",
      "    }\n",
      "  ],\n",
      "  \"file_set\": [\n",
      "    \"Wordscapes.txt\"\n",
      "  ],\n",
      "  \"query_rewriter\": [\n",
      "    {\n",
      "      \"best_file_path\": \"privacy_qa/Wordscapes.txt\",\n",
      "      \"file_locator\": \"\\\"Wordscapes\\\"'s privacy policy\",\n",
      "      \"similarity_score\": 0.7516341209411621,\n",
      "      \"only_question\": \"does it collect payment information\"\n",
      "    }\n",
      "  ],\n",
      "  \"feature_extraction\": [\n",
      "    {\n",
      "      \"query_complexity\": \"simple\",\n",
      "      \"retrieved_k\": 1\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Saved evaluation results to ../data/results/query_translation/privacy_qa.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "match_fn_embeddings = lambda tgt, files: find_best_corpus_embeddings(tgt, files, model)\n",
    "\n",
    "# Define the split function to use NER.\n",
    "# Jean-Baptiste/roberta-large-ner-english\n",
    "# dbmdz/bert-large-cased-finetuned-conll03-english\n",
    "ner_model = pipeline(\"ner\", model=\"Jean-Baptiste/roberta-large-ner-english\", aggregation_strategy=\"simple\")\n",
    "split_fn = lambda query: split_question_ner(query, ner_model)\n",
    "\n",
    "results = query_rewriter(groundtruth_tests, list_corpus, threshold, match_fn_embeddings, split_fn)\n",
    "\n",
    "for sample in random.sample(results, 5):\n",
    "    print(json.dumps(sample, indent=2))\n",
    "\n",
    "output_file = f\"../data/results/query_translation/{dataset_name}.json\"\n",
    "save_evaluation_results(results, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "privacy_qa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Evaluating queries: 100%|██████████| 192/192 [00:03<00:00, 48.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  privacy_qa\n",
      "Final Score:  Counter({1: 192})\n",
      "privacy_qa_rephrased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Evaluating queries: 100%|██████████| 192/192 [00:11<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  privacy_qa\n",
      "Final Score:  Counter({1: 109, 0: 83})\n",
      "privacy_qa_generic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Evaluating queries: 100%|██████████| 192/192 [00:10<00:00, 18.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  privacy_qa\n",
      "Final Score:  Counter({0: 166, 1: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [\"\", \"rephrased\", \"generic\"]:\n",
    "    if t==\"rephrased\":\n",
    "        curr_file = rephrased_file\n",
    "        dataset_type = \"_rephrased\"\n",
    "    elif t==\"generic\":\n",
    "        curr_file = generic_file\n",
    "        dataset_type = \"_generic\"\n",
    "    else:\n",
    "        curr_file = test_file\n",
    "        dataset_type = \"\"\n",
    "\n",
    "    print(dataset_name+dataset_type)\n",
    "    groundtruth_tests = load_groundtruth(curr_file) # test_file, rephrased_file, generic_file\n",
    "    test_queries = [gt.query for gt in groundtruth_tests]\n",
    "    list_corpus = [os.path.join(f\"{dataset_name}\", filename) for filename in os.listdir(directory_path) if filename.endswith(\".txt\")]\n",
    "\n",
    "    threshold = 0.3\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    match_fn_embeddings = lambda tgt, files: find_best_corpus_embeddings(tgt, files, model)\n",
    "\n",
    "    # Define the split function to use NER.\n",
    "    # Jean-Baptiste/roberta-large-ner-english\n",
    "    # dbmdz/bert-large-casedz-finetuned-conll03-english\n",
    "    ner_model = pipeline(\"ner\", model=\"Jean-Baptiste/roberta-large-ner-english\", aggregation_strategy=\"simple\")\n",
    "    split_fn = lambda query: split_question_ner(query, ner_model)\n",
    "\n",
    "    results = evaluate_corpus_matching(groundtruth_tests, list_corpus, threshold, match_fn_embeddings, split_fn)\n",
    "\n",
    "    with open(f\"../data/results/query_rewriter/NER_{dataset_name}{dataset_type}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    # for sample in random.sample(results, 5):\n",
    "    #     print(json.dumps(sample, indent=2))\n",
    "\n",
    "    scores = [results[i][\"score\"] for i in range(len(results))]\n",
    "    counts = Counter(scores)\n",
    "    print(\"dataset: \", dataset_name)\n",
    "    print(\"Final Score: \", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rephrase Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional\n",
    "from transformers import pipeline\n",
    "\n",
    "def rephrase_question(question: str, model, custom_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Rephrases a question into a more natural, real-world style while preserving two distinct parts:\n",
    "      - A part providing details about the relevant document or agreement (targeted corpus).\n",
    "      - The actual query regarding that document.\n",
    "      \n",
    "    The function uses prompt engineering with a few-shot approach. The output is expected to be exactly the rephrased question.\n",
    "    \n",
    "    Few-shot examples:\n",
    "    Example 1:\n",
    "      Original: \"In the Non-Disclosure Agreement between CopAcc and ToP Mentors, does it explicitly state that the Receiving Party is not granted any rights to the Confidential Information?\"\n",
    "      Rephrased: \"In the Non-Disclosure Agreement between CopAcc and ToP Mentors, does it explicitly state that the Receiving Party is not granted any rights to the Confidential Information?\"\n",
    "      \n",
    "    Example 2:\n",
    "      Original: \"Consider EFCA's Non-Disclosure Agreement; Does the document mention that some obligations of the Agreement may survive the termination of the Agreement?\"\n",
    "      Rephrased: \"Does EFCA's Non-Disclosure Agreement mention whether certain obligations continue even after the Agreement is terminated?\"\n",
    "      \n",
    "    Example 3:\n",
    "      Original: \"Consider the Data Use Agreement in New York City; Does the document specify whether the Receiving Party is required to destroy or return Confidential Information upon the termination of the Agreement?\"\n",
    "      Rephrased: \"In the Data Use Agreement for New York City, does the document specify if the Receiving Party must destroy or return Confidential Information once the Agreement ends?\"\n",
    "    \n",
    "    Now rephrase the following question:\n",
    "      Original: \"{question}\"\n",
    "    \n",
    "    Output exactly as:\n",
    "      Rephrased: \"<your rephrased question here>\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use sampling to allow creative rephrasing.\n",
    "    prompt = custom_prompt.format(question=question)\n",
    "    output = model(prompt, max_length=150, do_sample=True, temperature=0.8)\n",
    "    generated_text = output[0]['generated_text']\n",
    "    \n",
    "    # Attempt to parse the output if it follows our exact format\n",
    "    # Here we assume the model's output starts with \"Rephrased:\" and then the text.\n",
    "    if generated_text.strip().lower().startswith(\"rephrased:\"):\n",
    "        rephrased = generated_text.strip()[len(\"Rephrased:\"):].strip()\n",
    "    else:\n",
    "        rephrased = generated_text.strip()\n",
    "    \n",
    "    return rephrased\n",
    "\n",
    "def rephrase_groundtruth_queries(groundtruths: List[QAGroundTruth],\n",
    "                                 model,\n",
    "                                 percentage: float = 0.5,\n",
    "                                 custom_prompt: Optional[str] = None) -> List[QAGroundTruth]:\n",
    "    \"\"\"\n",
    "    Rephrases a given percentage of ground truth queries using the specified model and custom prompt.\n",
    "    \n",
    "    Args:\n",
    "      groundtruths: List of QAGroundTruth objects.\n",
    "      model: A text-to-text generation pipeline.\n",
    "      percentage: Fraction of queries to rephrase.\n",
    "      custom_prompt: A custom prompt string with a {question} placeholder.\n",
    "      \n",
    "    Returns:\n",
    "      The updated list of QAGroundTruth objects with rephrased queries.\n",
    "    \"\"\"\n",
    "    if custom_prompt is None:\n",
    "        # Fallback default prompt.\n",
    "        custom_prompt = (\n",
    "            \"Example 1:\\n\"\n",
    "            \"Original: \\\"Consider the Non-Disclosure Agreement between CopAcc and ToP Mentors; Does the document indicate that the Agreement does not grant any rights to the Confidential Information?\\\"\\n\"\n",
    "            \"Rephrased: \\\"In the Non-Disclosure Agreement between CopAcc and ToP Mentors, does it explicitly state that the Receiving Party is not granted any rights to the Confidential Information?\\\"\\n\\n\"\n",
    "            \"Example 2:\\n\"\n",
    "            \"Original: \\\"Consider EFCA's Non-Disclosure Agreement; Does the document mention that some obligations of the Agreement may survive the termination of the Agreement?\\\"\\n\"\n",
    "            \"Rephrased: \\\"Does EFCA's Non-Disclosure Agreement mention whether certain obligations continue even after the Agreement is terminated?\\\"\\n\\n\"\n",
    "            \"Example 3:\\n\"\n",
    "            \"Original: \\\"Consider the Data Use Agreement in New York City; Does the document specify whether the Receiving Party is required to destroy or return Confidential Information upon the termination of the Agreement?\\\"\\n\"\n",
    "            \"Rephrased: \\\"In the Data Use Agreement for New York City, does the document specify if the Receiving Party must destroy or return Confidential Information once the Agreement ends?\\\"\\n\\n\"\n",
    "            \"Now, rephrase the following question in a natural, conversational style while preserving the two parts (the document details and the query):\\n\"\n",
    "            \"Original: \\\"{question}\\\"\\n\\n\"\n",
    "            \"Rephrased: \"\n",
    "        )\n",
    "\n",
    "    num_to_rephrase = int(len(groundtruths) * percentage)\n",
    "    indices = random.sample(range(len(groundtruths)), num_to_rephrase)\n",
    "    \n",
    "    for idx in tqdm(indices, desc=\"Rephrasing queries\"):\n",
    "        original_query = groundtruths[idx].query\n",
    "        new_query = rephrase_question(original_query, model, custom_prompt)\n",
    "        groundtruths[idx].query = new_query\n",
    "    return groundtruths\n",
    "\n",
    "def save_groundtruth(groundtruths: List[QAGroundTruth], output_path: str):\n",
    "    \"\"\"\n",
    "    Saves the list of QAGroundTruth objects to a JSON file in the expected format.\n",
    "    \"\"\"\n",
    "    tests = [gt.dict() for gt in groundtruths]\n",
    "    output_data = {\"tests\": tests}\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "    print(f\"Saved rephrased groundtruth data to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import openai\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # This will load variables from .env into os.environ\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def rephrase_question_openai(question: str,\n",
    "                        custom_prompt: str,\n",
    "                        model: str = \"gpt-3.5-turbo\",\n",
    "                        max_tokens: int = 150,\n",
    "                        temperature: float = 0.8) -> str:\n",
    "    \"\"\"\n",
    "    Rephrases a question using the OpenAI API.\n",
    "    \n",
    "    The custom_prompt should contain a {question} placeholder that will be replaced with the original question.\n",
    "    \n",
    "    Example custom_prompt:\n",
    "    \"Example 1:\\n\"\n",
    "    \"Original: \\\"Consider the Non-Disclosure Agreement between CopAcc and ToP Mentors; Does the document indicate that the Agreement does not grant any rights to the Confidential Information?\\\"\\n\"\n",
    "    \"Rephrased: \\\"In the Non-Disclosure Agreement between CopAcc and ToP Mentors, does it explicitly state that the Receiving Party is not granted any rights to the Confidential Information?\\\"\\n\\n\"\n",
    "    \"Example 2:\\n\"\n",
    "    \"Original: \\\"Consider EFCA's Non-Disclosure Agreement; Does the document mention that some obligations of the Agreement may survive the termination of the Agreement?\\\"\\n\"\n",
    "    \"Rephrased: \\\"Does EFCA's Non-Disclosure Agreement mention whether certain obligations continue even after the Agreement is terminated?\\\"\\n\\n\"\n",
    "    \"Example 3:\\n\"\n",
    "    \"Original: \\\"Consider the Data Use Agreement in New York City; Does the document specify whether the Receiving Party is required to destroy or return Confidential Information upon the termination of the Agreement?\\\"\\n\"\n",
    "    \"Rephrased: \\\"In the Data Use Agreement for New York City, does the document specify if the Receiving Party must destroy or return Confidential Information once the Agreement ends?\\\"\\n\\n\"\n",
    "    \"Now, rephrase the following question in a natural, conversational style while preserving the two parts (the document details and the query):\\n\"\n",
    "    \"Original: \\\"{question}\\\"\\n\\n\"\n",
    "    \"Rephrased: \"\n",
    "    \n",
    "    The function expects the output to start with \"Rephrased:\" and then the rephrased text.\n",
    "    \"\"\"\n",
    "    prompt = custom_prompt.format(question=question)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that rephrases questions.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        n=1,\n",
    "    )\n",
    "    generated_text = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    \n",
    "    # Remove a \"Rephrased:\" prefix if present.\n",
    "    if generated_text.lower().startswith(\"rephrased:\"):\n",
    "        rephrased = generated_text[len(\"Rephrased:\"):].strip()\n",
    "    else:\n",
    "        rephrased = generated_text.strip()\n",
    "    return rephrased\n",
    "\n",
    "def rephrase_groundtruth_queries_openai(groundtruths: List[QAGroundTruth],\n",
    "                                 percentage: float = 0.5,\n",
    "                                 custom_prompt: Optional[str] = None,\n",
    "                                 model: str = \"gpt-3.5-turbo\",\n",
    "                                 max_tokens: int = 150,\n",
    "                                 temperature: float = 0.8) -> List[QAGroundTruth]:\n",
    "    \"\"\"\n",
    "    Rephrases a given percentage of queries in the ground truth using the OpenAI API.\n",
    "    \n",
    "    Args:\n",
    "      groundtruths: List of QAGroundTruth objects.\n",
    "      percentage: Fraction of queries to rephrase (e.g., 0.5 means 50%).\n",
    "      custom_prompt: A custom prompt string with a {question} placeholder.\n",
    "      model: The OpenAI model name.\n",
    "      max_tokens: Maximum tokens for the API call.\n",
    "      temperature: Sampling temperature.\n",
    "    \n",
    "    Returns:\n",
    "      The updated list of QAGroundTruth objects with rephrased queries.\n",
    "    \"\"\"\n",
    "    if custom_prompt is None:\n",
    "        custom_prompt = (\n",
    "            \"Example 1:\\n\"\n",
    "            \"Original: \\\"Consider the Non-Disclosure Agreement between CopAcc and ToP Mentors; Does the document indicate that the Agreement does not grant any rights to the Confidential Information?\\\"\\n\"\n",
    "            \"Rephrased: \\\"In the Non-Disclosure Agreement between CopAcc and ToP Mentors, does it explicitly state that the Receiving Party is not granted any rights to the Confidential Information?\\\"\\n\\n\"\n",
    "            \"Example 2:\\n\"\n",
    "            \"Original: \\\"Consider EFCA's Non-Disclosure Agreement; Does the document mention that some obligations of the Agreement may survive the termination of the Agreement?\\\"\\n\"\n",
    "            \"Rephrased: \\\"Does EFCA's Non-Disclosure Agreement mention whether certain obligations continue even after the Agreement is terminated?\\\"\\n\\n\"\n",
    "            \"Example 3:\\n\"\n",
    "            \"Original: \\\"Consider the Data Use Agreement in New York City; Does the document specify whether the Receiving Party is required to destroy or return Confidential Information upon the termination of the Agreement?\\\"\\n\"\n",
    "            \"Rephrased: \\\"In the Data Use Agreement for New York City, does the document specify if the Receiving Party must destroy or return Confidential Information once the Agreement ends?\\\"\\n\\n\"\n",
    "            \"Now, rephrase the following question in a natural, conversational style while preserving the two parts (the document details and the query):\\n\"\n",
    "            \"Original: \\\"{question}\\\"\\n\\n\"\n",
    "            \"Rephrased: \"\n",
    "        )\n",
    "    \n",
    "    num_to_rephrase = int(len(groundtruths) * percentage)\n",
    "    indices = random.sample(range(len(groundtruths)), num_to_rephrase)\n",
    "    \n",
    "    for idx in tqdm(indices, desc=\"Rephrasing queries\"):\n",
    "        original_query = groundtruths[idx].query\n",
    "        new_query = rephrase_question_openai(original_query, custom_prompt, model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "        groundtruths[idx].query = new_query\n",
    "    return groundtruths\n",
    "\n",
    "def save_groundtruth(groundtruths: List[QAGroundTruth], output_path: str):\n",
    "    \"\"\"\n",
    "    Saves the list of QAGroundTruth objects to a JSON file in the expected format.\n",
    "    \"\"\"\n",
    "    tests = [gt.dict() for gt in groundtruths]\n",
    "    output_data = {\"tests\": tests}\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "    print(f\"Saved rephrased groundtruth data to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rephrase into natural conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rephrased_prompt = (\n",
    "    \"Below are examples of how to naturally rephrase formal queries while keeping both the document reference and the main question intact. The rephrasings vary in sentence structure to enhance readability and conversational flow:\\n\\n\"\n",
    "    \n",
    "    \"Example 1:\\n\"\n",
    "    \"Original: \\\"Consider the Non-Disclosure Agreement between CopAcc and ToP Mentors; Does the document indicate that the Agreement does not grant any rights to the Confidential Information?\\\"\\n\"\n",
    "    \"Rephrased: \\\"In the Non-Disclosure Agreement between CopAcc and ToP Mentors, is it clearly stated that the Receiving Party has no rights to the Confidential Information?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Example 2:\\n\"\n",
    "    \"Original: \\\"Consider EFCA's Non-Disclosure Agreement; Does the document mention that some obligations of the Agreement may survive the termination of the Agreement?\\\"\\n\"\n",
    "    \"Rephrased: \\\"EFCA’s Non-Disclosure Agreement outlines various obligations—does it specify whether any of them remain in effect even after termination?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Example 3:\\n\"\n",
    "    \"Original: \\\"Consider the Data Use Agreement in New York City; Does the document specify whether the Receiving Party is required to destroy or return Confidential Information upon the termination of the Agreement?\\\"\\n\"\n",
    "    \"Rephrased: \\\"According to the Data Use Agreement in New York City, what happens to Confidential Information when the agreement ends? Is the Receiving Party required to return or destroy it?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Example 4:\\n\"\n",
    "    \"Original: \\\"Consider the Licensing Agreement between TechCorp and SoftInc; Does the document define any restrictions on sublicensing the software to third parties?\\\"\\n\"\n",
    "    \"Rephrased: \\\"The Licensing Agreement between TechCorp and SoftInc addresses various aspects of software usage. Does it impose any restrictions on sublicensing to third parties?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Example 5:\\n\"\n",
    "    \"Original: \\\"Consider the Employment Contract for senior engineers at InnovateX; Does the document clarify if employees are subject to a non-compete clause after resignation?\\\"\\n\"\n",
    "    \"Rephrased: \\\"For senior engineers at InnovateX, does the Employment Contract include a non-compete clause that remains in effect after resignation?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Now, rephrase the following question in a natural, conversational style while preserving the two parts (the document details and the query):\\n\"\n",
    "    \"Original: \\\"{question}\\\"\\n\\n\"\n",
    "    \"Rephrased: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Rephrasing queries:   0%|          | 0/192 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "Rephrasing queries: 100%|██████████| 192/192 [13:16<00:00,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Groupon\"'s privacy policy will allow third parties to view and track my personal information; can they see the code that i entered on a groupon??\"\n",
      "\"Is it ok if I leave the gps in the car with \"Keep\"?\"\n",
      "\"Groupon\"'s privacy policy is pretty confusing; does it need my location at all times, or can i just type in it whenever i'm looking for a coupon?\"\n",
      "\"Keep\" has a privacy policy, does it access any of my contacts information?\"\n",
      "\"Groupon\" is a marketing company for the use of Groupon coupons. What is it's policy on the use of data? (eg, does it sell it to third parties?)\n",
      "Saved rephrased groundtruth data to ../data/sample_benchmarks_rephrased/privacy_qa.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/hk/j9r7jggx4dxgt8gmzj_c2z080000gn/T/ipykernel_69772/2789246184.py:110: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  tests = [gt.dict() for gt in groundtruths]\n"
     ]
    }
   ],
   "source": [
    "# Load the ground truth test data from a JSON file.\n",
    "groundtruths_sample = f\"../data/{'sample_' if _use_sample else ''}benchmarks/{dataset_name}.json\"\n",
    "groundtruths = load_groundtruth(groundtruths_sample)\n",
    "\n",
    "# Load a text-to-text generation pipeline using an open-source model.\n",
    "model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "\n",
    "# Rephrase a specified percentage (e.g., 50%) of the queries.\n",
    "rephrased_groundtruths = rephrase_groundtruth_queries(groundtruths, model, percentage=1, custom_prompt=rephrased_prompt)\n",
    "\n",
    "for i in random.sample(rephrased_groundtruths, 5):\n",
    "    print(i.query)\n",
    "\n",
    "# Save the updated groundtruth test data.\n",
    "rephrased_file = f\"../data/{'sample_' if _use_sample else ''}benchmarks_rephrased/{dataset_name}.json\"\n",
    "save_groundtruth(rephrased_groundtruths, rephrased_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruths_rephrased = load_groundtruth(rephrased_file)\n",
    "\n",
    "len(groundtruths_rephrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rephrasing queries:   0%|          | 0/194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rephrasing queries: 100%|██████████| 194/194 [02:37<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rephrased groundtruth data to ../data/sample_benchmarks_rephrased/maud.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/hk/j9r7jggx4dxgt8gmzj_c2z080000gn/T/ipykernel_69772/2789246184.py:110: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  tests = [gt.dict() for gt in groundtruths]\n"
     ]
    }
   ],
   "source": [
    "# Load the ground truth test data from a JSON file.\n",
    "groundtruths_sample = f\"../data/{'sample_' if _use_sample else ''}benchmarks/{dataset_name}.json\"\n",
    "groundtruths = load_groundtruth(groundtruths_sample)\n",
    "\n",
    "# Rephrase a specified percentage (e.g., 50%) of the queries.\n",
    "rephrased_groundtruths = rephrase_groundtruth_queries_openai(groundtruths, model = \"gpt-3.5-turbo\", percentage=1, custom_prompt=rephrased_prompt, max_tokens=200)\n",
    "\n",
    "# Save the updated groundtruth test data.\n",
    "rephrased_file = f\"../data/{'sample_' if _use_sample else ''}benchmarks_rephrased/{dataset_name}.json\"\n",
    "save_groundtruth(rephrased_groundtruths, rephrased_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QAGroundTruth(query='\"In the Acquisition Agreement between Parent company LVMH Moët Hennessy-Louis Vuitton SE and Target company Tiffany & Co., could you clarify the definition of a \\'Superior Proposal\\'?\"', snippets=[QASnippet(file_path='maud/TIFFANY_&_CO._LVMH_MOËT_HENNESSY-LOUIS_VUITTON.txt', span=(14257, 15627), answer='“Acquisition Proposal” means any (a) proposal, offer, inquiry or indication of interest (whether in writing or otherwise) relating to a merger, joint venture, partnership, consolidation, dissolution, liquidation, tender offer, recapitalization, reorganization, spin-off, share exchange, asset purchase, extraordinary dividend, business combination or similar transaction involving the Company or any of its Subsidiaries or (b) direct or indirect acquisition (whether by tender offer, share purchase, share exchange or other manner) in a single transaction or a series of related transactions by any Person or group (as defined under Section 13 of the Exchange Act), or any proposal, offer, inquiry or indication of interest with respect to any such direct or indirect acquisition, which, in each case of (a) or (b), if consummated would result in any Person or group (as defined under Section 13 of the Exchange Act) becoming the beneficial owner of, directly or indirectly, in one or a series of related transactions, fifteen percent (15%) or more (i) measured by either voting power or value, of the Shares and other equity and voting interests in the Company (or any class thereof) or (ii) of the revenue, net income, EBITDA or assets of the Company and its Subsidiaries (taken as a whole), in each case, other than the transactions contemplated by this Agreement.   '), QASnippet(file_path='maud/TIFFANY_&_CO._LVMH_MOËT_HENNESSY-LOUIS_VUITTON.txt', span=(56585, 57627), answer='“Superior Proposal” means an unsolicited, bona fide written Acquisition Proposal (with all references to fifteen percent (15%) in the definition of Acquisition Proposal deemed to reference eighty and 1/10th percent (80.1%)) that the Company Board has determined in good faith (after consultation with a financial advisor (of nationally recognized reputation) and outside legal counsel), taking into account all financial, legal, regulatory and other aspects of such Acquisition Proposal and this Agreement, (a) to be reasonably likely to be consummated in accordance with its terms and (b) would result in a transaction more favorable to the stockholders of the Company (solely in their capacities as such) from a financial point of view than the transactions contemplated by this Agreement (after taking into account any revisions to the terms of this Agreement proposed by Parent pursuant to Section 7.3(d)(ii)); provided that such Acquisition Proposal was not obtained or made as a direct or indirect result of a breach of Section 7.3. \\n\\n\\n')]),\n",
       " QAGroundTruth(query='\"In the Acquisition Agreement between Parent company \\'LVMH Moët Hennessy-Louis Vuitton SE\\' and Target \\'Tiffany & Co.\\', could you explain the meaning of the term \\'Intervening Event\\'?\"', snippets=[QASnippet(file_path='maud/TIFFANY_&_CO._LVMH_MOËT_HENNESSY-LOUIS_VUITTON.txt', span=(38219, 40005), answer='“Intervening Event” means any event, occurrence, fact, condition, change, development, circumstance or effect or cause thereof (“Effect”) occurring or arising after the date of this Agreement that is material to the Company and its Subsidiaries, taken as a whole, and (a) was not known to, or reasonably foreseeable by, the Company Board as of or prior to the execution of this Agreement (or if known or reasonably foreseeable, the material consequences of which were not known or reasonably foreseeable by the Company Board), which Effect, or any material consequence thereof, becomes known to, or reasonably foreseeable by, the Company Board prior to the time the Requisite Company Vote is obtained and (b) does not in any way involve or relate to (i) an Acquisition Proposal, (ii) any changes in the market price or trading volume of the Company or Parent or the major stock indexes in the U.S. market, (iii) any changes in the Company’s credit ratings, (iv) the Company or Parent meeting, failing to meet or exceeding published or unpublished revenue or market consensus earnings projections, in each case in and of itself or (v) any changes or conditions generally affecting the economies or the industries in which the Company and its Subsidiaries operate, except to the extent such Effect has a materially disproportionate effect on the Company and its Subsidiaries, taken as a whole, relative to others in such industries in respect of the business conducted in such industries (it being understood that with respect to each of the foregoing clauses (i) through (iv) the Effect giving rise or contributing to such change or event may be taken into account when determining whether an Intervening Event has occurred to the extent not otherwise excluded from this definition). \\n\\n\\n')]),\n",
       " QAGroundTruth(query='\"In the Acquisition Agreement between Parent company LVMH Moët Hennessy-Louis Vuitton SE and Target company Tiffany & Co., could you provide details about the triggers for termination related to the Fiduciary Termination Right?\"', snippets=[QASnippet(file_path='maud/TIFFANY_&_CO._LVMH_MOËT_HENNESSY-LOUIS_VUITTON.txt', span=(302239, 302392), answer='9.3 Termination by the Company. This Agreement may be terminated and the transactions contemplated by this Agreement may be abandoned by the Company: \\n\\n\\n'), QASnippet(file_path='maud/TIFFANY_&_CO._LVMH_MOËT_HENNESSY-LOUIS_VUITTON.txt', span=(303544, 303889), answer='(b) prior to the time the Requisite Company Vote is obtained, to enter into an Alternative Acquisition Agreement in compliance with the terms of this Agreement, including Section 7.3(d)(ii); provided that the Company pays the Company Termination Fee to Parent prior to or concurrently with such termination in accordance with Section 9.5(b). \\n\\n\\n')]),\n",
       " QAGroundTruth(query='\"In the Acquisition Agreement between parent company LVMH Moët Hennessy-Louis Vuitton SE and target company Tiffany & Co., does the agreement include a Tail provision regarding acquisition proposals?\"', snippets=[QASnippet(file_path='maud/TIFFANY_&_CO._LVMH_MOËT_HENNESSY-LOUIS_VUITTON.txt', span=(304295, 304341), answer='9.5 Effect of Termination and Abandonment. \\n\\n\\n'), QASnippet(file_path='maud/TIFFANY_&_CO._LVMH_MOËT_HENNESSY-LOUIS_VUITTON.txt', span=(305380, 306495), answer='(b) The Company shall pay to Parent, by wire transfer of immediately available funds, a termination fee in the amount of $575,000,000 (the “Company Termination Fee”) in the event that this Agreement is terminated: \\n\\n\\n(i) by either the Company or Parent pursuant to Section 9.2(a), or Section 9.2(b) and, in each case; \\n\\n\\n(A) any Person shall have made an Acquisition Proposal to the Company or its stockholders (whether or not conditional or not withdrawn) or publicly announced an intention (whether or not conditional and whether or not withdrawn) to make an Acquisition Proposal with respect to the Company or any of its Subsidiaries, and \\n\\n\\n(B) within twelve (12) months after such termination, the Company enters into any Alternative Acquisition Agreement with respect to any Acquisition Proposal (with “fifty percent (50%)” being substituted in lieu of “fifteen percent (15%)” in each instance thereof in the definition of “Acquisition Proposal” for purposes of this Section 9.5(b)(i)(B)), then immediately prior to or concurrently with the occurrence of such entry into an Alternative Acquisition Agreement, ')]),\n",
       " QAGroundTruth(query='\"In the Acquisition Agreement between Parent \"LVMH Moët Hennessy-Louis Vuitton SE\" and Target \"Tiffany & Co.,\" what exactly are the Ordinary Course of Business covenants?\"', snippets=[QASnippet(file_path='maud/TIFFANY_&_CO._LVMH_MOËT_HENNESSY-LOUIS_VUITTON.txt', span=(46004, 46511), answer='“Ordinary Course of Business” means, with respect to any Person, the conduct by a Person of the relevant business in the ordinary course, which in the case of the Company or any of its Subsidiaries shall be deemed to include, without limitation, the manner in which the Company and its Subsidiaries have been operating at any time since the Original Signing Date through the date of this Agreement and any COVID-19 Measures taken by the Company and its Subsidiaries following the date of this Agreement. \\n\\n\\n'), QASnippet(file_path='maud/TIFFANY_&_CO._LVMH_MOËT_HENNESSY-LOUIS_VUITTON.txt', span=(199960, 200984), answer='7.1 Conduct of the Company. \\n\\n\\n(a) From and after the execution and delivery of this Agreement until the earlier to occur of the Effective Time or the termination of this Agreement in accordance with Article IX, the Company shall, and shall cause each of its Subsidiaries to, except as set forth in Section 7.1(a)(i)-(xxiv) of the Company Disclosure Letter, consented to in writing by Parent (such consent (x) not to be unreasonably conditioned, withheld or delayed and (y) to be provided as set forth in Section 7.2), previously approved in writing by Parent pursuant to the Original Merger Agreement or in compliance with a Company Material Contract, and except (A) as otherwise specifically contemplated by this Agreement, (B) as is required by a Governmental Entity or applicable Law or (C) COVID-19 Measures, (1) comply in all material respects with all applicable Laws and the material requirements of all Company Material Contracts and conduct its business in all material respects in the Ordinary Course of Business ')])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rephrased_groundtruths[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruths_rephrased = load_groundtruth(rephrased_file)\n",
    "\n",
    "len(groundtruths_rephrased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rephrase into general questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Rephrasing queries: 100%|██████████| 60/60 [03:45<00:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rephrased groundtruth data to ../data/sample_benchmarks/contractnli_rephrased_split_3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/hk/j9r7jggx4dxgt8gmzj_c2z080000gn/T/ipykernel_17242/441073255.py:95: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  tests = [gt.dict() for gt in groundtruths]\n"
     ]
    }
   ],
   "source": [
    "general_prompt = (\n",
    "    \"Example 1:\\n\"\n",
    "    \"Original: \\\"Consider the Non-Disclosure Agreement between CopAcc and ToP Mentors; Does the document indicate that the Agreement does not grant the Receiving Party any rights to the Confidential Information?\\\"\\n\"\n",
    "    \"Rephrased: \\\"Does a Non-Disclosure Agreement typically state that the Receiving Party has no rights to the Confidential Information shared under the agreement?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Example 2:\\n\"\n",
    "    \"Original: \\\"Consider EFCA's Non-Disclosure Agreement; Does the document mention that some obligations of the Agreement may survive the termination of the Agreement?\\\"\\n\"\n",
    "    \"Rephrased: \\\"Do Non-Disclosure Agreements often include clauses specifying whether certain obligations continue even after the agreement is terminated?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Example 3:\\n\"\n",
    "    \"Original: \\\"Consider the Data Use Agreement in New York City; Does the document specify whether the Receiving Party is required to destroy or return Confidential Information upon the termination of the Agreement?\\\"\\n\"\n",
    "    \"Rephrased: \\\"Is it common for Data Use Agreements to require the Receiving Party to destroy or return Confidential Information when the agreement ends?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Now, rephrase the following question into a more GENERAL query, removing specific references to particular agreements while keeping the essence of the legal or contractual inquiry:\\n\"\n",
    "    \"Original: \\\"{question}\\\"\\n\\n\"\n",
    "    \"Rephrased: \"\n",
    ")\n",
    "\n",
    "# Load the ground truth test data from a JSON file.\n",
    "groundtruths_sample3 = f\"../data/{'sample_' if _use_sample else ''}benchmarks/{dataset_name}.json\"\n",
    "groundtruths = load_groundtruth(groundtruths_sample3)\n",
    "\n",
    "# Load a text-to-text generation pipeline using an open-source model.\n",
    "model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "\n",
    "# Rephrase a specified percentage (e.g., 50%) of the queries.\n",
    "rephrased_groundtruths = rephrase_groundtruth_queries(groundtruths, model, percentage=1, custom_prompt=general_prompt)\n",
    "\n",
    "# Save the updated groundtruth test data.\n",
    "rephrased_file = f\"../data/{'sample_' if _use_sample else ''}benchmarks_generic/{dataset_name}.json\"\n",
    "save_groundtruth(rephrased_groundtruths, rephrased_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "query='\"Do the terms of Grindrod SA\\'s Non-Disclosure Agreement state that Confidential Information shall only include technical information?\"' snippets=[QASnippet(file_path='contractnli/Grindrod%20SA%20Confidentiality%20and%20Non-Disclosure%20Undertaking.txt', span=(757, 1492), answer='1.1 “Confidential Information” means; all technical, commercial, procurement requirements, purchasing, manufacturing, customer lists, investors, employees, business and contractual relationships, business forecasts, sales and merchandising, and marketing plans business or personnel information disclosed or otherwise made available in any format and/or physical manner by Grindrod SA or becoming available, before, during and/or after the execution of an interaction, duty or obligation including all information that makes itself known to the Vendor or comes into being as a result of the rendering, production and/or delivery of an agreement/understanding/request for quotation/contract or Purchase Order, or any other interaction. ')]\n",
      "query='\"Does a non-disclosure agreement typically state that the receiving party has no rights to the Confidential Information shared under the agreement?\"' snippets=[QASnippet(file_path='contractnli/CopAcc_NDA-and-ToP-Mentors_2.0_2017.txt', span=(11461, 11963), answer='Any and all proprietary rights, including but not limited to rights to and in inventions, patent rights, utility models, copyrights, trademarks and trade secrets, in and to any Confidential Information shall be and remain with the Participants respectively, and Mentor shall not have any right, license, title or interest in or to any Confidential Information, except the limited right to review, assess and help develop such Confidential Information in connection with the Copernicus Accelerator 2017.')]\n",
      "query='\"Does DBT\\'s Mutual Non-Disclosure Agreement restrict the use of Confidential Information to the purposes stated in the Agreement??\"' snippets=[QASnippet(file_path='contractnli/DBT%20Mutual%20NDA.txt', span=(2723, 2947), answer='Each party agrees that it shall not make use of, disseminate, or in any way disclose any Confidential Information of the Disclosing Party to any person, firm, or business, except to the extent necessary for the Transaction. ')]\n",
      "query='\"The Non-Disclosure Agreement between IGC and LSE does not include a clause that prevents the Receiving Party from disclosing the fact that the Agreement was agreed upon or negotiated?\"' snippets=[QASnippet(file_path='contractnli/IGC-Non-Disclosure-Agreement-LSE-Sample.txt', span=(2636, 3052), answer=\"Confidential Information means all confidential information (however recorded, preserved or disclosed) disclosed by a party or its Representatives to the other party and that party's Representatives including but not limited to:\\n(a) The fact that discussions and negotiations are taking place concerning the Purpose and the status of those discussions and negotiations;\\n(b) The existence and terms of this Agreement;\"), QASnippet(file_path='contractnli/IGC-Non-Disclosure-Agreement-LSE-Sample.txt', span=(8385, 9060), answer=\"No party shall make, or permit any person to make, any public announcement concerning this Agreement, the Purpose or its prospective interest in the Purpose without the prior written consent of the other party (such consent not to be unreasonably withheld or delayed) except as required by law or any governmental or regulatory authority (including, without limitation, any relevant securities exchange) or by any court or other authority of competent jurisdiction. No party shall make use of the other party's name or any information acquired through its dealings with the other party for publicity or marketing purposes without the prior written consent of the other party.\")]\n",
      "query='\"Does the confidentiality provision of the Confidential Information agreement in Euler Hermes allow the Receiving Party to share some Confidential Information with their employees?\"' snippets=[QASnippet(file_path='contractnli/eulerhermes-nda.txt', span=(1794, 2026), answer='1. Euler Hermes shall keep the Confidential Information confidential and may disclose the Confidential Information only to its Affiliates, employees, contractors, or consultants for the Purpose described above and no other purpose. ')]\n"
     ]
    }
   ],
   "source": [
    "groundtruths_rephrased = load_groundtruth(rephrased_file)\n",
    "\n",
    "print(len(groundtruths_rephrased))\n",
    "for i in groundtruths_rephrased[:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rephrasing queries: 100%|██████████| 192/192 [02:01<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rephrased groundtruth data to ../data/sample_benchmarks_generic/privacy_qa.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/hk/j9r7jggx4dxgt8gmzj_c2z080000gn/T/ipykernel_69772/2789246184.py:110: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  tests = [gt.dict() for gt in groundtruths]\n"
     ]
    }
   ],
   "source": [
    "general_prompt = (\n",
    "    \"Example 1:\\n\"\n",
    "    \"Original: \\\"Consider the Non-Disclosure Agreement between CopAcc and ToP Mentors; Does the document indicate that the Agreement does not grant the Receiving Party any rights to the Confidential Information?\\\"\\n\"\n",
    "    \"Rephrased: \\\"Does a Non-Disclosure Agreement typically state that the Receiving Party has no rights to the Confidential Information shared under the agreement?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Example 2:\\n\"\n",
    "    \"Original: \\\"Consider EFCA's Non-Disclosure Agreement; Does the document mention that some obligations of the Agreement may survive the termination of the Agreement?\\\"\\n\"\n",
    "    \"Rephrased: \\\"Do Non-Disclosure Agreements often include clauses specifying whether certain obligations continue even after the agreement is terminated?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Example 3:\\n\"\n",
    "    \"Original: \\\"Consider the Data Use Agreement in New York City; Does the document specify whether the Receiving Party is required to destroy or return Confidential Information upon the termination of the Agreement?\\\"\\n\"\n",
    "    \"Rephrased: \\\"Is it common for Data Use Agreements to require the Receiving Party to destroy or return Confidential Information when the agreement ends?\\\"\\n\\n\"\n",
    "    \n",
    "    \"Now, rephrase the following question into a more general query, minimising specific references to particular agreements while keeping the essence of the legal or contractual inquiry, don't use the same pattern as 'Is it common ..', keep the question vary:\\n\"\n",
    "    \"Original: \\\"{question}\\\"\\n\\n\"\n",
    "    \"Rephrased: \"\n",
    ")\n",
    "\n",
    "# Load the ground truth test data from a JSON file.\n",
    "groundtruths_sample3 = f\"../data/{'sample_' if _use_sample else ''}benchmarks/{dataset_name}.json\"\n",
    "groundtruths = load_groundtruth(groundtruths_sample3)\n",
    "\n",
    "# Rephrase a specified percentage (e.g., 50%) of the queries.\n",
    "rephrased_groundtruths = rephrase_groundtruth_queries_openai(groundtruths, model = \"gpt-3.5-turbo\", percentage=1, custom_prompt=general_prompt, max_tokens=200)\n",
    "\n",
    "# Save the updated groundtruth test data.\n",
    "rephrased_file = f\"../data/{'sample_' if _use_sample else ''}benchmarks_generic/{dataset_name}.json\"\n",
    "save_groundtruth(rephrased_groundtruths, rephrased_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "query='\"Within Non-Disclosure Agreements, is it typically specified that the definition of Confidential Information is limited to technical details?\"' snippets=[QASnippet(file_path='contractnli/Grindrod%20SA%20Confidentiality%20and%20Non-Disclosure%20Undertaking.txt', span=(757, 1492), answer='1.1 “Confidential Information” means; all technical, commercial, procurement requirements, purchasing, manufacturing, customer lists, investors, employees, business and contractual relationships, business forecasts, sales and merchandising, and marketing plans business or personnel information disclosed or otherwise made available in any format and/or physical manner by Grindrod SA or becoming available, before, during and/or after the execution of an interaction, duty or obligation including all information that makes itself known to the Vendor or comes into being as a result of the rendering, production and/or delivery of an agreement/understanding/request for quotation/contract or Purchase Order, or any other interaction. ')]\n",
      "query='\"Typically, do Non-Disclosure Agreements specify that the Receiving Party does not have rights to the Confidential Information shared under the agreement?\"' snippets=[QASnippet(file_path='contractnli/CopAcc_NDA-and-ToP-Mentors_2.0_2017.txt', span=(11461, 11963), answer='Any and all proprietary rights, including but not limited to rights to and in inventions, patent rights, utility models, copyrights, trademarks and trade secrets, in and to any Confidential Information shall be and remain with the Participants respectively, and Mentor shall not have any right, license, title or interest in or to any Confidential Information, except the limited right to review, assess and help develop such Confidential Information in connection with the Copernicus Accelerator 2017.')]\n",
      "query='\"Are Non-Disclosure Agreements typically designed to limit the use of Confidential Information to specific purposes outlined in the agreement?\"' snippets=[QASnippet(file_path='contractnli/DBT%20Mutual%20NDA.txt', span=(2723, 2947), answer='Each party agrees that it shall not make use of, disseminate, or in any way disclose any Confidential Information of the Disclosing Party to any person, firm, or business, except to the extent necessary for the Transaction. ')]\n",
      "query='\"Are Non-Disclosure Agreements typically designed to prevent the Receiving Party from disclosing the details of how the agreement was reached or negotiated?\"' snippets=[QASnippet(file_path='contractnli/IGC-Non-Disclosure-Agreement-LSE-Sample.txt', span=(2636, 3052), answer=\"Confidential Information means all confidential information (however recorded, preserved or disclosed) disclosed by a party or its Representatives to the other party and that party's Representatives including but not limited to:\\n(a) The fact that discussions and negotiations are taking place concerning the Purpose and the status of those discussions and negotiations;\\n(b) The existence and terms of this Agreement;\"), QASnippet(file_path='contractnli/IGC-Non-Disclosure-Agreement-LSE-Sample.txt', span=(8385, 9060), answer=\"No party shall make, or permit any person to make, any public announcement concerning this Agreement, the Purpose or its prospective interest in the Purpose without the prior written consent of the other party (such consent not to be unreasonably withheld or delayed) except as required by law or any governmental or regulatory authority (including, without limitation, any relevant securities exchange) or by any court or other authority of competent jurisdiction. No party shall make use of the other party's name or any information acquired through its dealings with the other party for publicity or marketing purposes without the prior written consent of the other party.\")]\n",
      "query='\"Are recipients typically permitted to disclose certain Confidential Information to their employees in Non-Disclosure Agreements?\"' snippets=[QASnippet(file_path='contractnli/eulerhermes-nda.txt', span=(1794, 2026), answer='1. Euler Hermes shall keep the Confidential Information confidential and may disclose the Confidential Information only to its Affiliates, employees, contractors, or consultants for the Purpose described above and no other purpose. ')]\n"
     ]
    }
   ],
   "source": [
    "groundtruths_rephrased = load_groundtruth(rephrased_file)\n",
    "\n",
    "print(len(groundtruths_rephrased))\n",
    "for i in groundtruths_rephrased[:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample queries into 3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 194 queries.\n",
      "Saved 60 queries to ../data/sample_benchmarks/contractnli_split_1.json\n",
      "Saved 60 queries to ../data/sample_benchmarks/contractnli_split_2.json\n",
      "Saved 60 queries to ../data/sample_benchmarks/contractnli_split_3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hk/j9r7jggx4dxgt8gmzj_c2z080000gn/T/ipykernel_17242/3158612484.py:8: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  tests = [gt.dict() for gt in groundtruths]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def save_groundtruth(groundtruths: List[QAGroundTruth], output_path: str):\n",
    "    \"\"\"\n",
    "    Saves a list of QAGroundTruth objects to a JSON file in the expected format.\n",
    "    \"\"\"\n",
    "    tests = [gt.dict() for gt in groundtruths]\n",
    "    output_data = {\"tests\": tests}\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "    print(f\"Saved {len(groundtruths)} queries to {output_path}\")\n",
    "\n",
    "\n",
    "groundtruths = load_groundtruth(test_file)\n",
    "print(f\"Loaded {len(groundtruths)} queries.\")\n",
    "\n",
    "# Shuffle the queries randomly.\n",
    "random.shuffle(groundtruths)\n",
    "\n",
    "# Split the list into 3 nearly equal parts.\n",
    "chunks = [groundtruths[i:i+60] for i in range(0, 180, 60)]\n",
    "\n",
    "# Save each chunk to a separate file.\n",
    "for i, chunk in enumerate(chunks, start=1):\n",
    "    splitted_file = f\"../data/{'sample_' if _use_sample else ''}benchmarks/{dataset_name}_split_{i}.json\"\n",
    "    save_groundtruth(chunk, splitted_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
