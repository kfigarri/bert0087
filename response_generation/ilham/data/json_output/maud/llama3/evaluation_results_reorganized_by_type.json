{
    "baseline": {
        "k1": {
            "ragas_metrics": "{'faithfulness': 0.5606, 'answer_relevancy': 0.6413}",
            "bert_f1": 0.7125173661204958,
            "rouge_recall": 0.4049775169431745
        },
        "k3": {
            "ragas_metrics": "{'faithfulness': 0.6627, 'answer_relevancy': 0.6777}",
            "bert_f1": 0.6978954132070246,
            "rouge_recall": 0.19125560819048587
        },
        "k5": {
            "ragas_metrics": "{'faithfulness': 0.6755, 'answer_relevancy': 0.3796}",
            "bert_f1": 0.6553537498429879,
            "rouge_recall": 0.12203020885986397
        },
        "k10": {
            "ragas_metrics": "{'faithfulness': 0.7820, 'answer_relevancy': 0.5342}",
            "bert_f1": 0.6537933235930413,
            "rouge_recall": 0.058316600075759395
        }
    },
    "CoT": {
        "k1": {
            "ragas_metrics": "{'faithfulness': 0.4586, 'answer_relevancy': 0.5561}",
            "bert_f1": 0.7031079263416762,
            "rouge_recall": 0.41647683373755023
        },
        "k3": {
            "ragas_metrics": "{'faithfulness': 0.6386, 'answer_relevancy': 0.5756}",
            "bert_f1": 0.7039549618037706,
            "rouge_recall": 0.2272626748701277
        },
        "k5": {
            "ragas_metrics": "{'faithfulness': 0.4946, 'answer_relevancy': 0.5004}",
            "bert_f1": 0.6699866895208654,
            "rouge_recall": 0.15868394658546256
        },
        "k10": {
            "ragas_metrics": "{'faithfulness': 0.6582, 'answer_relevancy': 0.4745}",
            "bert_f1": 0.6411110930836078,
            "rouge_recall": 0.05506290184258426
        }
    },
    "manually_written": {
        "k1": {
            "ragas_metrics": "{'faithfulness': 0.5815, 'answer_relevancy': 0.4065}",
            "bert_f1": 0.7253389272493186,
            "rouge_recall": 0.788815498807449
        },
        "k3": {
            "ragas_metrics": "{'faithfulness': 0.7180, 'answer_relevancy': 0.4909}",
            "bert_f1": 0.7396247390004778,
            "rouge_recall": 0.5179333624722443
        },
        "k5": {
            "ragas_metrics": "{'faithfulness': 0.7593, 'answer_relevancy': 0.4509}",
            "bert_f1": 0.7502514050178921,
            "rouge_recall": 0.4204730471833718
        },
        "k10": {
            "ragas_metrics": "{'faithfulness': 0.8482, 'answer_relevancy': 0.4855}",
            "bert_f1": 0.6970822331831628,
            "rouge_recall": 0.17138959020679218
        }
    }
}